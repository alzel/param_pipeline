
default: &DEFAULT
  #shuffle: True
  #model_load: True


  epochs: [1]
  #early stopping
  min_delta: [0.01]
  patience: [50]

  #learning rate scheduler
  #lrs: [True]
  #lrs_epoch_drop: [10]

  lr: [0.01]
  beta_1: [0.95]
  beta_2: [0.9995]
  epsilon: [1e-7]
  mbatch: [64, 128, 256]
  dropout: [0.6]
  #lrs_threshod: [20]
  #lrs_drop: [0.3]

   #activation: ["relu"]
  #optimizer: ["Adam"]
  #replicates
  replicate_seed: [100]
  #configs_n: 3
  #random_seed: 1111

sampling:
  <<: *DEFAULT
  # variable
  lr:
      ub: np.log(0.1) #alphaH
      lb: np.log(0.0001) #alphaL
      type: log
  beta_1:
      ub: 0.95 #betaH
      lb: 0.5 #betaL
      type: uniform
  beta_2:
      ub: np.log(0.95)
      lb: np.log(0.9)
      type: log
#  lrs_threshold:
#      ub: 50
#      lb: 0
#      n: 1
#  lrs_drop:
#      ub: 0.99
#      lb: 0
#      n: 1

#mbatchL: 16
#mbatchH: 1024 # multiples of x2
#dropoutL: 0.00
#dropoutH: 0.50 # 0.xx resolution

#lrs_tresholdL: 0
#lrs_tresholdH: 50 # resolution 1
#lrs_dropL: 0.00
#lrs_dropH: 0.99