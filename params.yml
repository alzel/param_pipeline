
default: &DEFAULT
  epochs: [3]
  #early stopping
  min_delta: [0.01]
  patience: [50]

  #learning rate scheduler
  #lrs: [True]
  #lrs_epoch_drop: [10]

  lr: [0.01]
  beta_1: [0.95]
  beta_2: [0.9995]
  epsilon: [1e-7]
  mbatch: [64, 128, 256]
  replicate_seed: [100]

sampling:
  <<: *DEFAULT
  # variable
  lr:
      ub: np.log(0.1) #alphaH
      lb: np.log(0.00001) #alphaL
      type: log
  beta_1:
      ub: 0.95 #betaH
      lb: 0.5 #betaL
      type: uniform
  beta_2:
      ub: np.log(0.95)
      lb: np.log(0.9)
      type: log
#  lrs_threshold:
#      ub: 50
#      lb: 0
#      n: 1
#  lrs_drop:
#      ub: 0.99
#      lb: 0
#      n: 1

#mbatchL: 16
#mbatchH: 1024 # multiples of x2
#dropoutL: 0.00
#dropoutH: 0.50 # 0.xx resolution

#lrs_tresholdL: 0
#lrs_tresholdH: 50 # resolution 1
#lrs_dropL: 0.00
#lrs_dropH: 0.99

